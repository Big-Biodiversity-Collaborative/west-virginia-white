---
title: "West Virginia White"
author: "Jeff Oliver"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

<!--
TODO: Need to consider sampling only a portion for each year.
-->

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(ggplot2))

# Establish bootstrap and sampling values
minimum.required <- 5
sample.size <- minimum.required
num.bs.reps <- 1000
```

## Preliminary analyses

"Preliminary"" does not do it justice. This is very, very back of the envelope. Data are from iNaturalist observations downloaded on 2 May 2019 and GBIF data downloaded on 17 May 2019.

```{r load-prepare-data}
# Read in iNaturalist observations
# 52539 is West Virginia White
iNaturalist <- read.csv(file = "data/observations-52593.csv")
iNat.obs <- iNaturalist[, c("latitude", "longitude", "observed_on")]
iNat.obs$observed_on <- as.Date(iNat.obs$observed_on)

# Read in GBIF observations
gbif <- read.delim(file = "data/0015022-190415153152247.csv")
gbif.obs <- gbif[, c("decimalLatitude", "decimalLongitude", "eventDate")]
gbif.obs$eventDate <- as.Date(x = gbif.obs$eventDate)
gbif.obs <- na.omit(gbif.obs)

# Join data sets
colnames(iNat.obs) <- c("latitude", "longitude", "date")
colnames(gbif.obs) <- c("latitude", "longitude", "date")
wvw <- rbind(iNat.obs, gbif.obs)

# Remove some bad geo coordinates (mostly GBIF)
wvw <- wvw[wvw$latitude > 29, ]
wvw <- wvw[wvw$longitude > -100, ]

# Extract year and day of year
wvw$year <- year(wvw$date)
wvw$yday <- as.POSIXlt(wvw$date)$yday

# Dates of January 1 (yday == 0) are not realistic
wvw <- wvw[wvw$yday > 0, ]
# Drop any from current, incomplete year
wvw <- wvw[wvw$year != year(today()), ]

# Drop duplicates
wvw <- unique(wvw)
```

After dropping some unrealistic GBIF observations (some from the Indian Ocean some from January 1) and those from `r year(today())`, there are `r nrow(wvw)` observations. If we plot these by year and day of year, it looks like recently there may have been a shift to earlier emergences:

```{r plot-data}
# Plot observations for each year separately
obs.plot <- ggplot(data = wvw, mapping = aes(x = year, y = yday, color = latitude)) +
  geom_point() +
  geom_smooth() +
  xlab(label = "Year") +
  ylab(label = "Day") +
  ggtitle("P. virginiensis")
suppressMessages(expr = print(obs.plot))
```

Note that observations from lower latitudes (darker points) are generally towards the bottom of the plot, and observations from more northern latitudes (lighter points) are nearer the top of the plot. No big surprise there.

## Earliest emergences

If we only consider the earliest emergences,

```{r plot-minimums}
# Plot _only_ minimums
wvw.mins <- wvw %>%
  group_by(year) %>%
  summarise(early = min(yday, na.rm = TRUE),
            n.obs = n())

min.plot.title <- paste0("Earliest observations, ", 
                     min(wvw$year), " - ", 
                     max(wvw$year))
min.plot <- ggplot(data = wvw.mins, mapping = aes(x = year, y = early)) +
  geom_point() +
  geom_smooth()  +
  xlab(label = "Year") +
  ylab(label = "Day") +
  ggtitle(min.plot.title) + 
  theme_bw()
suppressMessages(expr = print(min.plot))
```

There _is_ a trend towards earlier emergences in more recent years, so let's consider a very crude linear model:
$$
Earliest \enspace observation \enspace day_i = Year_i + \epsilon_i
$$

```{r minimums-model}
# Linear regression 
early.lm <- lm(early ~ year, data = wvw.mins)
early.summary <- summary(early.lm)
year.coeff <- early.summary$coefficients[2, 1]
year.p <- early.summary$coefficients[2, 4]
```

There is an effect of year on earliest observation date, with the first earliest observation occuring `r abs(round(year.coeff, digits = 2))` days earlier each year (p = `r round(year.p, digits = 4)`).

## But...

Given the increase in butterfly watching, this change in observations could be entirely due to sampling artifacts than biological reality. Consider the number of observations of _P. virginiensis_ through time:

```{r wvw-obs-plot}
wvw.plot.title <- paste0("Number of observations per year, ", 
                     min(wvw$year), " - ", 
                     max(wvw$year))

wvw.plot <- ggplot(data = wvw.mins, mapping = aes(x = year, y = n.obs)) +
  geom_point() +
  geom_smooth()  +
  xlab(label = "Year") +
  ylab(label = "Observations") +
  ggtitle(wvw.plot.title) + 
  theme_bw()
suppressMessages(expr = print(wvw.plot))
```

Pretty clearly increasing. So this means that by chance, recent years are more likely to "catch" earlier observations, just because there are more opportunities. To see this in action, consider a thought experiment where we make up data. Well, bootstrapping data, but it's nearly the same thing. If we create a data set that mimics the observation efforts for the observed data (i.e. `r wvw.mins$n.obs[1]` in `r wvw.mins$year[1]`, `r wvw.mins$n.obs[floor(nrow(wvw.mins)/2)]` in `r wvw.mins$year[floor(nrow(wvw.mins)/2)]`, `r wvw.mins$n.obs[nrow(wvw.mins)]` in `r wvw.mins$year[nrow(wvw.mins)]`, etc.), but instead of actual observations, sample only from the most recent year of observations (`r wvw.mins$year[nrow(wvw.mins)]`). We then use those data to run the linear regression again and see if there is an effect. Ideally, if there is _no_ artifact of sampling, we should see, on average, no effect of year on earliest observation (this is because, for these data, _all_ days of observation are being drawn from the "real" data for `r wvw.mins$year[nrow(wvw.mins)]` alone). Repeating this process `r num.bs.reps` times should result, on average, of an effect size of 0:

```{r plot-ideal}
sample.from <- wvw$yday[wvw$year == 2018]
include.years <- wvw.mins$year[wvw.mins$n.obs >= minimum.required]
wvw.for.bs <- wvw[wvw$year %in% include.years, ]

# Replicate process of sampling and linear regression
bs.results <- data.frame(replicate = 1:num.bs.reps,
                         estimate = NA,
                         p.value = NA)
for (r in 1:num.bs.reps) {
  # Data fram will hold bootstrapped data
  bootstrapped.df <- data.frame(year = rep(include.years, times = sample.size),
                                yday = NA)
  # Fill in data frame with bootstrapped date for each year
  for (yr in include.years) {
    bootstrapped.df$yday[bootstrapped.df$year == yr] <- sample(x = sample.from,
                                                               size = sample.size,
                                                               replace = FALSE)
  }

  bs.mins <- bootstrapped.df %>%
    group_by(year) %>%
    summarise(early = min(yday))
  
  bs.lm <- lm(early ~ year, data = bs.mins)
  bs.results$estimate[r] <- summary(bs.lm)$coefficients[2, 1]
  bs.results$p.value[r] <- summary(bs.lm)$coefficients[2, 4]
}

# Plot results of bootstrapping
# Coefficient estimates
estimate.plot <- ggplot(data = bs.results, mapping = aes(x = estimate)) +
  geom_histogram() +
  geom_vline(xintercept = 0) +
  xlab(label = "Effect size (days/year)") +
  ylab(label = "Count") +
  ggtitle(label = "Expectation in artifact-free world") +
  theme_bw()
suppressMessages(expr = print(estimate.plot))
```

However, when we do the bootstrapping experiment, it looks like there is considerable potential for an artifact:

```{r demostrate-artifact}
# Set up number of reps and distribution to sample from
sample.from <- wvw$yday[wvw$year == 2018]
include.years <- wvw.mins$year[wvw.mins$n.obs >= minimum.required]
wvw.for.bs <- wvw[wvw$year %in% include.years, ]

# Replicate process of sampling and linear regression
bs.results <- data.frame(replicate = 1:num.bs.reps,
                         estimate = NA,
                         p.value = NA)

for (r in 1:num.bs.reps) {
  # Erase values in yday; these will be replaced via bootstrap sampling
  wvw.for.bs$yday <- NA
  # Should be a tidyverse way of doing this...
  for (y in unique(wvw.for.bs$year)) {
    num.obs <- sum(wvw.for.bs$year == y)
    wvw.for.bs$yday[wvw.for.bs$year == y] <- sample(x = sample.from, size = num.obs)
  }
  bs.mins <- wvw.for.bs %>%
    group_by(year) %>%
    summarise(early = min(yday))
  
  suppressMessages(expr = bs.lm <- lm(early ~ year, data = bs.mins))
  bs.results$estimate[r] <- summary(bs.lm)$coefficients[2, 1]
  bs.results$p.value[r] <- summary(bs.lm)$coefficients[2, 4]
}

# Plot results of bootstrapping
# Coefficient estimates
estimate.plot <- ggplot(data = bs.results, mapping = aes(x = estimate)) +
  geom_histogram() +
  geom_vline(xintercept = 0, color = "#FF0000") +
  xlab(label = "Effect size (days/year)") +
  ylab(label = "Count") +
  ggtitle(label = "Artifact of increasing sampling effort through time") +
  theme_bw()
suppressMessages(expr = print(estimate.plot))
```

And the mean effect size is observations are getting earlier by `r abs(round(mean(bs.results$estimate, na.rm = TRUE), digits = 2))` days per year. We know this is an artifact because all the data are based on `r wvw.mins$year[nrow(wvw.mins)]`.

## Back to the bootstrap

However, we can use bootstrapping to down-sample observations to make effort across years consistent. That is, for each year, we randomly sample a subset of observations so we only have a certain number of observations per year. For that "certain number", we'll a minimum of `r minimum.required` observations per year. Let's test this first by doing the same process we ran before, basing everying on data from `r wvw.mins$year[nrow(wvw.mins)]` alone, but now only drawing `r sample.size` samples for each year. Ideally, we should see no effect of year on earliest observation (i.e. an effect size of 0).

```{r bootstrap-proof-of-concept}
sample.from <- wvw$yday[wvw$year == 2018]
include.years <- wvw.mins$year[wvw.mins$n.obs >= minimum.required]
wvw.for.bs <- wvw[wvw$year %in% include.years, ]

# Replicate process of sampling and linear regression
bs.results <- data.frame(replicate = 1:num.bs.reps,
                         estimate = NA,
                         p.value = NA)
for (r in 1:num.bs.reps) {
  # Data fram will hold bootstrapped data
  bootstrapped.df <- data.frame(year = rep(include.years, times = sample.size),
                                yday = NA)
  # Fill in data frame with bootstrapped date for each year
  for (yr in include.years) {
    bootstrapped.df$yday[bootstrapped.df$year == yr] <- sample(x = sample.from,
                                                               size = sample.size,
                                                               replace = FALSE)
  }

  bs.mins <- bootstrapped.df %>%
    group_by(year) %>%
    summarise(early = min(yday))
  
  bs.lm <- lm(early ~ year, data = bs.mins)
  bs.results$estimate[r] <- summary(bs.lm)$coefficients[2, 1]
  bs.results$p.value[r] <- summary(bs.lm)$coefficients[2, 4]
}

# Plot results of bootstrapping
# Coefficient estimates
estimate.plot <- ggplot(data = bs.results, mapping = aes(x = estimate)) +
  geom_histogram() +
  geom_vline(xintercept = 0) +
  xlab(label = "Effect size (days/year)") +
  ylab(label = "Count") +
  ggtitle(label = "Downsampling to avoid artifacts") + 
  theme_bw()
suppressMessages(expr = print(estimate.plot))
```

Woo-hoo! So now we have a way to avoid artifacts due to variation in effort. Let's try it for real, downsampling each years' data to only `r minimum.required` per year.Before we try that, what effect does this restriction of `r minimum.required` observations per year have on the size of our data set? We had `r nrow(wvw)` observations, but if we restrict it to only those years with at least `r minimum.required` observations, we have `r nrow(wvw.for.bs)` total observations, spanning `r min(wvw.for.bs$year)` through `r max(wvw.for.bs$year)`. Taking a look at these data:

```{r reduced-data-plot}
# TODO: Make a two-panel plot, one with observations, one with earliest observations
wvw.for.bs <- wvw[wvw$year %in% include.years, ]

obs.plot.title <- paste0("P. virginiensis, ",
                         min(wvw.for.bs$year), " - ", 
                         max(wvw.for.bs$year))
obs.plot <- ggplot(data = wvw.for.bs, mapping = aes(x = year, 
                                                    y = yday, 
                                                    color = latitude)) +
  geom_point() +
  geom_smooth() +
  xlab(label = "Year") +
  ylab(label = "Day") +
  ggtitle(obs.plot.title)
suppressMessages(expr = print(obs.plot))
```

```{r downsample-and-test}

```